import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
from PIL import Image, ImageOps 
from flask import Flask, request, jsonify

# æ–°å¢ï¼šå»èƒŒéœ€è¦çš„å‡½å¼åº«
from rembg import remove 

# Segmentation éœ€è¦çš„å‡½å¼åº«
import cv2
import numpy as np
import base64
from ultralytics import YOLO
import datetime

app = Flask(__name__)

# --- è¨­å®šè·¯å¾‘ ---
CLS_MODEL_PATH = "models/Half Data.pth"  
SEG_MODEL_PATH = "models/yolo11n-seg.pt"

UPLOAD_FOLDER = "uploads"
DEBUG_FOLDER = "debug_images"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)
if not os.path.exists(DEBUG_FOLDER):
    os.makedirs(DEBUG_FOLDER)

# --- 1. é¡åˆ¥å®šç¾© ---
CLASSES = [
    'å±±è—¥', 'å·èŠ', 'æœ¨é¦™', 'ç†Ÿåœ°', 'ç”˜è‰', 
    'ç™½èŠ·', 'ç´…è€†', 'èªæœ®', 'è’¼æœ®', 'é™³çš®', 'é»ƒè€†'
]

LABEL_TO_KEY_MAP = {
    'å±±è—¥': 'Dioscorea polystachya Turcz',
    'å·èŠ': 'Ligusticum chuanxiong Hort',
    'æœ¨é¦™': 'Radix Aucklandiae',
    'ç†Ÿåœ°': 'Prepared Rehmannia Root',
    'ç”˜è‰': 'Licorice',
    'ç™½èŠ·': 'Dahurian Angelica',
    'ç´…è€†': 'Hedysarum Root',
    'èªæœ®': 'Zedoary Rhizome',
    'è’¼æœ®': 'Atractylodes Rhizome',
    'é™³çš®': 'Citri Reticulatae Pericarpium',
    'é»ƒè€†': 'Astragalus membranaceus'
}

# --- 2. è¼‰å…¥ Classification æ¨¡å‹ ---
def load_classification_model():
    print("æ­£åœ¨è¼‰å…¥ Classification æ¨¡å‹ (EfficientNet-B2)...")
    try:
        weights = models.EfficientNet_B2_Weights.IMAGENET1K_V1
        model = models.efficientnet_b2(weights=weights)
    except:
        print("âš ï¸ ç„¡æ³•è¼‰å…¥ ImageNet é è¨“ç·´æ¬Šé‡ï¼Œä½¿ç”¨ç©ºæ¶æ§‹")
        model = models.efficientnet_b2(weights=None)

    for param in model.parameters(): 
      param.requires_grad = False

    in_features = model.classifier[1].in_features
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.5), 
        nn.Linear(in_features, len(CLASSES))
    )
    
    try:
        checkpoint = torch.load(CLS_MODEL_PATH, map_location=DEVICE)
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
            
        model.load_state_dict(state_dict)
        model.to(DEVICE)
        model.eval()
        print(f"âœ… Classification æ¨¡å‹è¼‰å…¥æˆåŠŸï¼(é¡åˆ¥æ•¸: {len(CLASSES)})")
        return model
    except Exception as e:
        print(f"âŒ Classification æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None 

# --- 3. è¼‰å…¥ Segmentation æ¨¡å‹ ---
def load_segmentation_model():
    print(f"æ­£åœ¨è¼‰å…¥ Segmentation æ¨¡å‹ (YOLO): {SEG_MODEL_PATH}...")
    try:
        model = YOLO(SEG_MODEL_PATH)
        print("âœ… Segmentation æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        return model
    except Exception as e:
        print(f"âŒ Segmentation æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

cls_model = load_classification_model()
seg_model = load_segmentation_model()

# --- é è™•ç† ---
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# --- åˆ‡åœ–å‡½å¼ (Grid Split) ---
# é€™å°±æ˜¯ä½ èªªçš„ã€Œåˆ‡å‰²åœ–åƒã€ï¼Œä¿ç•™ä¸‹ä¾†ä¸¦ç”¨æ–¼å»èƒŒå¾Œçš„åœ–
def split_img(img, splits=4):
    result = []
    img_w, img_h = img.size
    
    step_w = int(img_w / splits)
    step_h = int(img_h / splits)

    for row in range(splits):
        for col in range(splits):
            left = col * step_w
            upper = row * step_h
            right = left + step_w
            lower = upper + step_h
            
            if col == splits - 1: right = img_w
            if row == splits - 1: lower = img_h

            box = (left, upper, right, lower)
            tile = img.crop(box)
            result.append(tile)
    return result

@app.route('/upload', methods=['POST'])
def predict_api():
    if 'file' not in request.files:
        return jsonify({'status': 'error', 'message': 'æœªå‚³é€æª”æ¡ˆ'}), 400
    
    file = request.files['file']
    mode = request.form.get('mode', 'Classification')
    
    try:
        # 1. é–‹å•Ÿåœ–ç‰‡ä¸¦åˆæ­¥è™•ç†
        image = Image.open(file)
        image = ImageOps.exif_transpose(image) # è‡ªå‹•è½‰æ­£
        
        # ç”¢ç”Ÿæ™‚é–“æˆ³è¨˜ (Debugç”¨)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

        # --- åˆ†æ”¯ 1: Classification (å»èƒŒ -> å¡«é»‘ -> åˆ‡åœ– -> æŠ•ç¥¨) ---
        if mode == 'Classification':
            if cls_model is None: return jsonify({'status': 'error', 'message': 'æ¨¡å‹æœªè¼‰å…¥'}), 500

            # === A. å»èƒŒä¸¦å¡«è£œé»‘åº• (ä½ æä¾›çš„æ–°é‚è¼¯) ===
            print("â³ æ­£åœ¨é€²è¡Œå»èƒŒè™•ç† (Rembg)...")
            
            # rembg.remove è¼¸å…¥å¯ä»¥æ˜¯ PIL Imageï¼Œå›å‚³ä¹Ÿæ˜¯ PIL Image (RGBA)
            no_bg_image = remove(image)
            
            # å°‡é€æ˜èƒŒæ™¯è½‰ç‚ºç´”é»‘è‰² (é¿å… CNN å°é€æ˜åº¦é€šé“æ„Ÿåˆ°å›°æƒ‘)
            # å»ºç«‹ä¸€å¼µå…¨é»‘çš„åº•åœ–
            final_image = Image.new("RGB", no_bg_image.size, (0, 0, 0))
            # å°‡å»èƒŒåœ–è²¼ä¸Šå»ï¼Œä½¿ç”¨ Alpha é€šé“ä½œç‚º Mask
            # split()[3] æ˜¯ Alpha channel
            if no_bg_image.mode == 'RGBA':
                final_image.paste(no_bg_image, mask=no_bg_image.split()[3])
            else:
                # å¦‚æœ rembg å›å‚³çš„ä¸æ˜¯ RGBA (ç½•è¦‹)ï¼Œå°±ç›´æ¥ç”¨ RGB
                final_image = no_bg_image.convert('RGB')

            # ğŸ“¸ å„²å­˜å»èƒŒå¾Œçš„åœ–ç‰‡ä¾›æª¢æŸ¥
            debug_path = os.path.join(DEBUG_FOLDER, f"{timestamp}_nobg.jpg")
            final_image.save(debug_path)
            print(f"âœ… å»èƒŒå®Œæˆï¼Œå·²å„²å­˜é™¤éŒ¯åœ–: {debug_path}")

            # === B. åˆ‡åœ– (4x4 = 16å¼µ) ===
            # ä½¿ç”¨å»èƒŒå¾Œçš„ final_image é€²è¡Œåˆ‡å‰²
            splits = 4
            tiles = split_img(final_image, splits=splits)
            
            # === C. é æ¸¬èˆ‡æŠ•ç¥¨ ===
            vote_box = {cls_name: 0.0 for cls_name in CLASSES}
            
            with torch.no_grad():
                for tile in tiles:
                    input_tensor = preprocess(tile).unsqueeze(0).to(DEVICE)
                    output = cls_model(input_tensor)
                    probs = F.softmax(output, dim=1)
                    
                    top_p, top_class = probs.topk(1, dim=1)
                    idx = top_class.item()
                    conf = top_p.item()
                    
                    # ç´¯åŠ ä¿¡å¿ƒåº¦
                    predicted_label = CLASSES[idx]
                    vote_box[predicted_label] += conf

            # === D. çµç®— ===
            sorted_votes = sorted(vote_box.items(), key=lambda item: item[1], reverse=True)
            winner_label = sorted_votes[0][0]
            total_score = sorted_votes[0][1]
            avg_confidence = total_score / (splits * splits)
            app_herb_id = LABEL_TO_KEY_MAP.get(winner_label, "Unknown")
            
            print(f"ğŸ† è¾¨è­˜çµæœ: {winner_label} (ç¸½åˆ†: {total_score:.2f})")

            return jsonify({
                'status': 'success',
                'result': {
                    'herb_id': app_herb_id,    
                    'confidence': avg_confidence, 
                    'chinese_name': winner_label
                }
            })

        # --- åˆ†æ”¯ 2: Segmentation (YOLO) ---
        elif mode == 'Segmentation':
            if seg_model is None: return jsonify({'status': 'error', 'message': 'æ¨¡å‹æœªè¼‰å…¥'}), 500
            
            # ç¢ºä¿å‚³å…¥çš„æ˜¯åŸå§‹åœ–ç‰‡ (RGB)
            seg_input = image.convert('RGB')
            
            results = seg_model.predict(source=seg_input, conf=0.25)
            
            if len(results) == 0 or len(results[0].boxes) == 0:
                annotated_frame = np.array(seg_input) 
                annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
            else:
                result = results[0]
                annotated_frame = result.plot() # é€™è£¡æœƒç•«å‡ºåˆ‡å‰²æ¡†å’Œé®ç½©

            retval, buffer = cv2.imencode('.jpg', annotated_frame)
            if retval:
                base64_string = base64.b64encode(buffer).decode('utf-8')
                return jsonify({
                    'status': 'success',
                    'result': {
                        'segmentation_image_base64': base64_string
                    }
                })
            else:
                return jsonify({'status': 'error', 'message': 'åœ–ç‰‡ç·¨ç¢¼å¤±æ•—'}), 500

    except Exception as e:
        print(f"âŒ Server éŒ¯èª¤: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == "__main__":
    if cls_model is None:
        print("âš ï¸ è­¦å‘Šï¼šClassification æ¨¡å‹æœªæˆåŠŸè¼‰å…¥")
        
    app.run(host='0.0.0.0', port=5001, debug=False)