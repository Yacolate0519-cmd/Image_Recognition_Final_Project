import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
from PIL import Image, ImageOps  # ğŸ‘ˆ æ–°å¢ ImageOps ç”¨ä¾†è™•ç†æ—‹è½‰
from flask import Flask, request, jsonify

# æ–°å¢ï¼šSegmentation éœ€è¦çš„å‡½å¼åº«
import cv2
import numpy as np
import base64
from ultralytics import YOLO
import datetime # ç”¨ä¾†ç”¢ç”Ÿæª”å

app = Flask(__name__)

# --- è¨­å®šè·¯å¾‘ ---
# CLS_MODEL_PATH = "models/model_v2.pth"
CLS_MODEL_PATH = "models/Model_1222.pth"
# SEG_MODEL_PATH = "models/seg.pt"
SEG_MODEL_PATH = "models/yolo11n-seg.pt"
UPLOAD_FOLDER = "uploads"
DEBUG_FOLDER = "debug_images"  # ğŸ‘ˆ æ–°å¢é™¤éŒ¯è³‡æ–™å¤¾ï¼Œè®“æˆ‘å€‘çœ‹çœ‹ Server åˆ°åº•æ”¶åˆ°äº†ä»€éº¼é¬¼
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)
if not os.path.exists(DEBUG_FOLDER):
    os.makedirs(DEBUG_FOLDER)

# --- é¡åˆ¥å®šç¾© (ä¿æŒä¸è®Š) ---
CLASSES = [
    'ä½•é¦–çƒ', 'å±±è—¥', 'å·èŠ', 'æœ¨é¦™', 'ç†Ÿåœ°', 
    'ç”˜è‰', 'ç™½æœ®ç‰‡', 'ç™½èŠ·', 'ç´…è€†', 'ç¾Šå¥¶é ­', 
    'èŒ¯è‹“', 'èªæœ®', 'è’¼æœ®ç‰‡', 'é™³çš®', 'é»ƒè€†'
]

LABEL_TO_KEY_MAP = {
    'ä½•é¦–çƒ': 'Fallopia multiflora',
    'å±±è—¥': 'Dioscorea polystachya Turcz',
    'å·èŠ': 'Ligusticum chuanxiong Hort',
    'æœ¨é¦™': 'Radix Aucklandiae',
    'ç†Ÿåœ°': 'Prepared Rehmannia Root',
    'ç”˜è‰': 'Licorice',
    'ç™½æœ®ç‰‡': 'Baizhu Slices',
    'ç™½èŠ·': 'Dahurian Angelica',
    'ç´…è€†': 'Hedysarum Root',
    'ç¾Šå¥¶é ­': 'Taiwan Ficus',
    'èŒ¯è‹“': 'Poria',
    'èªæœ®': 'Zedoary Rhizome',
    'è’¼æœ®ç‰‡': 'Atractylodes Rhizome',
    'é™³çš®': 'Citri Reticulatae Pericarpium',
    'é»ƒè€†': 'Astragalus membranaceus'
}


# --- 1. è¼‰å…¥ Classification æ¨¡å‹ ---
def load_classification_model():
    print("æ­£åœ¨è¼‰å…¥ Classification æ¨¡å‹ (EfficientNet)...")
    model = models.efficientnet_b2(weights=None)
    in_features = model.classifier[1].in_features
    
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.5), 
        nn.Linear(in_features, len(CLASSES))
    )
    
    try:
        # é€™è£¡åŠ å…¥ strict=False å¯ä»¥é¿å…ä¸€äº›å¾®å°çš„ key ä¸åŒ¹é…å•é¡Œï¼Œä½†ä¸å»ºè­°å¸¸é§
        checkpoint = torch.load(CLS_MODEL_PATH, map_location=DEVICE)
        
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
            
        model.load_state_dict(state_dict)
        model.to(DEVICE)
        model.eval()
        print("âœ… Classification æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        return model
    except Exception as e:
        print(f"âŒ Classification æ¨¡å‹è¼‰å…¥å¤±æ•— (åš´é‡): {e}")
        # å¦‚æœæ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œæˆ‘å€‘æ‡‰è©²è®“ç¨‹å¼å ±éŒ¯ï¼Œè€Œä¸æ˜¯ç¹¼çºŒåŸ·è¡Œ
        return None 

# --- 2. è¼‰å…¥ Segmentation æ¨¡å‹ ---
def load_segmentation_model():
    print(f"æ­£åœ¨è¼‰å…¥ Segmentation æ¨¡å‹ (YOLO): {SEG_MODEL_PATH}...")
    try:
        model = YOLO(SEG_MODEL_PATH)
        print("âœ… Segmentation æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        return model
    except Exception as e:
        print(f"âŒ Segmentation æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

cls_model = load_classification_model()
seg_model = load_segmentation_model()

# --- é è™•ç† ---
# âš ï¸ é‡è¦ç¢ºèªï¼šè«‹ç¢ºèªé€™è·Ÿæ‚¨ã€Œè¨“ç·´æ™‚ã€ä½¿ç”¨çš„é è™•ç†ä¸€æ¨¡ä¸€æ¨£
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

@app.route('/upload', methods=['POST'])
def predict_api():
    if 'file' not in request.files:
        return jsonify({'status': 'error', 'message': 'æœªå‚³é€æª”æ¡ˆ'}), 400
    
    file = request.files['file']
    mode = request.form.get('mode', 'Classification')
    
    try:
        # 1. é–‹å•Ÿåœ–ç‰‡
        image = Image.open(file)
        
        # ğŸ› ï¸ ä¿®æ­£é» 1ï¼šè‡ªå‹•ä¿®æ­£ EXIF æ—‹è½‰ (iOS ç…§ç‰‡å¿…å‚™)
        image = ImageOps.exif_transpose(image)
        
        # ç¢ºä¿è½‰ç‚º RGB (å»é™¤ Alpha é€šé“)
        image = image.convert('RGB')

        # ğŸ› ï¸ ä¿®æ­£é» 2ï¼šå„²å­˜ Server å¯¦éš›çœ‹åˆ°çš„åœ–ç‰‡ (ç”¨ä¾†é™¤éŒ¯)
        # è«‹å» debug_images è³‡æ–™å¤¾çœ‹ï¼Œåœ–ç‰‡æ˜¯ä¸æ˜¯é»‘çš„ï¼Ÿæ˜¯ä¸æ˜¯è½‰å‘äº†ï¼Ÿ
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        debug_path = os.path.join(DEBUG_FOLDER, f"{timestamp}_{mode}.jpg")
        image.save(debug_path)
        print(f"ğŸ“¸ å·²å„²å­˜é™¤éŒ¯åœ–ç‰‡: {debug_path}")

        # --- åˆ†æ”¯ 1: Classification ---
        if mode == 'Classification':
            if cls_model is None: return jsonify({'status': 'error', 'message': 'æ¨¡å‹æœªè¼‰å…¥'}), 500

            input_tensor = preprocess(image).unsqueeze(0).to(DEVICE)

            with torch.no_grad():
                output = cls_model(input_tensor)        
                probs = F.softmax(output, dim=1)
                
                # ğŸ› ï¸ ä¿®æ­£é» 3ï¼šå°å‡ºå‰ä¸‰åï¼Œè§€å¯Ÿæ˜¯ä¸æ˜¯ã€Œç”˜è‰ã€æ©Ÿç‡åªè´ä¸€é»é»
                # top3_prob, top3_class = probs.topk(3, dim=1)
                # print(f"ğŸ” Top 3 é æ¸¬:")
                # for i in range(3):
                #     idx = top3_class[0][i].item()
                #     prob = top3_prob[0][i].item()
                #     print(f"   {i+1}. {CLASSES[idx]} ({prob:.2%})")
                

                # å–ç¬¬ä¸€åå›å‚³
                top_p, top_class = probs.topk(1, dim=1)
                class_index = top_class.item()
                confidence = top_p.item()
                
                chinese_label = CLASSES[class_index]
                app_herb_id = LABEL_TO_KEY_MAP.get(chinese_label, "Unknown")

            return jsonify({
                'status': 'success',
                'result': {
                    'herb_id': app_herb_id,    
                    'confidence': confidence
                }
            })

        # --- åˆ†æ”¯ 2: Segmentation ---
        elif mode == 'Segmentation':
            if seg_model is None: return jsonify({'status': 'error', 'message': 'æ¨¡å‹æœªè¼‰å…¥'}), 500

            # ğŸ› ï¸ ä¿®æ­£é» 4ï¼šé™ä½ä¿¡å¿ƒé–€æª» (0.5 -> 0.25)
            # æ‰‹æ©Ÿæ‹æ”ç’°å¢ƒè¼ƒè¤‡é›œï¼Œ0.5 å¯èƒ½å¤ªåš´æ ¼
            results = seg_model.predict(source=image, conf=0.25)
            
            if len(results) == 0 or len(results[0].boxes) == 0:
                print("âš ï¸ åˆ†å‰²æ¨¡å¼ï¼šæœªåµæ¸¬åˆ°ä»»ä½•ç‰©ä»¶")
                # å°±ç®—æ²’æŠ“åˆ°ï¼Œä¹Ÿå›å‚³åŸåœ–çµ¦ä½¿ç”¨è€…çœ‹ï¼Œé¿å… App è½‰åœˆåœˆ
                annotated_frame = np.array(image) 
                # æ³¨æ„ï¼šPIL è½‰ numpy æ˜¯ RGBï¼ŒOpenCV ç·¨ç¢¼éœ€è¦ BGR
                annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
            else:
                result = results[0]
                print(f"âœ‚ï¸ åˆ†å‰²æ¨¡å¼ï¼šåµæ¸¬åˆ° {len(result.boxes)} å€‹ç‰©ä»¶")
                annotated_frame = result.plot() # plot å›å‚³çš„æ˜¯ BGR

            # è½‰ Base64
            retval, buffer = cv2.imencode('.jpg', annotated_frame)
            if retval:
                base64_string = base64.b64encode(buffer).decode('utf-8')
                return jsonify({
                    'status': 'success',
                    'result': {
                        'segmentation_image_base64': base64_string
                    }
                })
            else:
                return jsonify({'status': 'error', 'message': 'åœ–ç‰‡ç·¨ç¢¼å¤±æ•—'}), 500

    except Exception as e:
        print(f"âŒ Server éŒ¯èª¤: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=5001, debug=False)